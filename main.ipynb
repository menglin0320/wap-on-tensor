{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cPickle as pkl\n",
    "#import ipdb\n",
    "import numpy\n",
    "import copy\n",
    "import pprint\n",
    "from Recognizer import MathFormulaRecognizer\n",
    "import warnings\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "from util import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "from data_iterator import dataIterator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_path = os.getcwd()\n",
    "checkpoint_path = os.path.join(home_path,'save','model.ckpt')\n",
    "checkpoint_dir  =os.path.join(home_path,'save')\n",
    "max_iters = 100000\n",
    "batch_size = 16\n",
    "valid_batch_size = 8\n",
    "finetune_encoder_after = -1\n",
    "#Evaluation Checkpoint\n",
    "nEvaImages = 300\n",
    "EvaEach = 2500\n",
    "SummaryEach = 1000\n",
    "device = \"/gpu:0\"\n",
    "batch_Imagesize=250000\n",
    "valid_batch_Imagesize=500000\n",
    "maxImagesize = 500000\n",
    "maxlen = 200\n",
    "n_epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build model\n",
    "model = MathFormulaRecognizer(num_label =112,dim_hidden=128,device = '/device:GPU:0')\n",
    "loss,opt = model.build_train()\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "sess = tf.Session()\n",
    "saved_path=tf.train.latest_checkpoint(checkpoint_dir)\n",
    "start_step = 0\n",
    "if(saved_path):\n",
    "    tf.reset_default_graph()\n",
    "    saver.restore(sess, saved_path)\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir) \n",
    "    step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "    start_step = int(step)\n",
    "    print('model restored',start_step)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets=['./data/offline-train.pkl',\n",
    "'./data/train_caption.txt']\n",
    "valid_datasets=['./data/offline-test.pkl',\n",
    "'./data/test_caption.txt']\n",
    "dictionaries=['./data/dictionary.txt']\n",
    "\n",
    "\n",
    "worddicts = load_dict(dictionaries[0])\n",
    "worddicts_r = [None] * len(worddicts)\n",
    "\n",
    "for kk, vv in worddicts.iteritems():\n",
    "        worddicts_r[vv] = kk\n",
    "train,train_uid_list = dataIterator(datasets[0], datasets[1],\n",
    "                         worddicts,\n",
    "                         batch_size=batch_size, batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize)\n",
    "valid,valid_uid_list = dataIterator(valid_datasets[0], valid_datasets[1],\n",
    "                     worddicts,\n",
    "                     batch_size=valid_batch_size, batch_Imagesize=valid_batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.squeeze(train)\n",
    "valid = np.squeeze(valid)\n",
    "n_train_img = train.shape[0]\n",
    "n_valid_img = valid.shape[0]\n",
    "\n",
    "for i in range(start_step/n_train_img,n_epoch):\n",
    "    rand_permute = np.arange(n_train_img)\n",
    "    np.random.shuffle(rand_permute)\n",
    "    saver.save(sess, checkpoint_path, global_step=i*rand_permute.shape[0])\n",
    "    avg_loss = 0\n",
    "    count = 0\n",
    "    print('epoch: ',i)\n",
    "    for j in range(0,rand_permute.shape[0]):\n",
    "        x, x_mask, y, y_mask = prepare_data(train[rand_permute[j],0],train[rand_permute[j],1])\n",
    "        y = np.transpose(y)\n",
    "        y_mask = np.transpose(y_mask)\n",
    "        _,Loss = sess.run([opt,loss],feed_dict={model.x:x,model.x_mask:x_mask,model.y:y,\\\n",
    "                                                model.y_mask:y_mask,model.is_train:True,model.lr:0.002})\n",
    "        avg_loss = avg_loss + Loss\n",
    "        count = count + 1\n",
    "        if(not(j %100)):\n",
    "            avg_loss = avg_loss / count\n",
    "            print(j,avg_loss)\n",
    "            count = 0\n",
    "            avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# train = np.squeeze(train)\n",
    "# valid = np.squeeze(valid)\n",
    "# n_train_img = train.shape[0]\n",
    "# n_valid_img = valid.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(x_entropy)\n",
    "# plt.imshow(x_mask[0,:,:],cmap='gray')\n",
    "\n",
    "# # for i in range(0,len(train[800,0])):\n",
    "# #     print(train[800,0][i].shape)\n",
    "# im = train[0,0][2]\n",
    "# im = im.reshape(im.shape[1],im.shape[2])\n",
    "# plt.imshow(im,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(logit.shape)\n",
    "# np.argmax(logit,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
